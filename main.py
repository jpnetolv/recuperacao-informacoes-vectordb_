from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_ollama import OllamaEmbeddings, OllamaLLM
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA

def main():
    print("ðŸ”„ Carregando e processando o PDF...")
    loader = PyPDFLoader(r"data/PPC_TSI_EaD.pdf")
    pages = loader.load()
    print(f"âœ… Documento carregado e dividido em {len(pages)} pÃ¡ginas.")

    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    texts = splitter.split_documents(pages)
    print(f"âœ… Documento dividido em {len(texts)} chunks.")

    texts = texts[:10]  # modo teste rÃ¡pido para acelerar
    print("âš¡ Modo teste rÃ¡pido ativado: usando apenas 10 chunks.")

    print("ðŸ§® Criando embeddings...")
    embeddings = OllamaEmbeddings(model="llama2")
    print("âœ… Embeddings criados.")

    print("ðŸ§© Construindo Ã­ndice FAISS...")
    db = FAISS.from_documents(texts, embeddings)
    retriever = db.as_retriever()

    print("ðŸ¤– Configurando modelo Ollama LLM...")
    llm = OllamaLLM(model="llama2")

    qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

    print("\nâœ… Sistema pronto! FaÃ§a perguntas (digite 'sair' para encerrar):")
    while True:
        query = input("\nPergunta: ")
        if query.lower() in ("sair", "exit", "quit"):
            print("ðŸ‘‹ Encerrando.")
            break
        answer = qa.invoke({"query": query})["result"]
        print(f"\nResposta:\n{answer}")

if __name__ == "__main__":
    main()
